{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import (BatchNormalization, Conv1D, MaxPooling1D, Dense, Input, Dropout,\n",
    "    TimeDistributed, Activation, Bidirectional, SimpleRNN, GRU, LSTM, Reshape)\n",
    "\n",
    "def simple_rnn_model(input_dim, output_dim=29):\n",
    "    \"\"\" Build a recurrent network for speech \n",
    "    \"\"\"\n",
    "    # Main acoustic input\n",
    "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
    "    # Add recurrent layer\n",
    "    simp_rnn = GRU(output_dim, return_sequences=True, \n",
    "                 implementation=2, name='rnn')(input_data)\n",
    "    # Add softmax activation layer\n",
    "    y_pred = Activation('softmax', name='softmax')(simp_rnn)\n",
    "    # Specify the model\n",
    "    model = Model(inputs=input_data, outputs=y_pred)\n",
    "    model.output_length = lambda x: x\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "def rnn_model(input_dim, units, activation, output_dim=29):\n",
    "    \"\"\" Build a recurrent network for speech \n",
    "    \"\"\"\n",
    "    # Main acoustic input\n",
    "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
    "    # Add recurrent layer\n",
    "    simple_rnn = GRU(units, activation=activation,\n",
    "        return_sequences=True, implementation=2, name='rnn')(input_data)\n",
    "    # TODO: Add batch normalization \n",
    "    bn_rnn = BatchNormalization()(simple_rnn)\n",
    "    # TODO: Add a TimeDistributed(Dense(output_dim)) layer\n",
    "    time_dense = TimeDistributed(Dense(units=units))(bn_rnn)\n",
    "    # Add softmax activation layer\n",
    "    y_pred = Activation('softmax', name='softmax')(time_dense)\n",
    "    # Specify the model\n",
    "    model = Model(inputs=input_data, outputs=y_pred)\n",
    "    model.output_length = lambda x: x\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "def cnn_rnn_model(input_dim, filters, kernel_size, conv_stride,\n",
    "    conv_border_mode, units, output_dim=29):\n",
    "    \"\"\" Build a recurrent + convolutional network for speech \n",
    "    \"\"\"\n",
    "    # Main acoustic input\n",
    "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
    "    # Add convolutional layer\n",
    "    conv_1d = Conv1D(filters, kernel_size, \n",
    "                     strides=conv_stride, \n",
    "                     padding=conv_border_mode,\n",
    "                     activation='relu',\n",
    "                     name='conv1d')(input_data)\n",
    "    # Add batch normalization\n",
    "    bn_cnn = BatchNormalization(name='bn_conv_1d')(conv_1d)\n",
    "    # Add a recurrent layer\n",
    "    simple_rnn = SimpleRNN(units, activation='relu',\n",
    "        return_sequences=True, implementation=2, name='rnn')(bn_cnn)\n",
    "    # TODO: Add batch normalization\n",
    "    bn_rnn = BatchNormalization()(simple_rnn)\n",
    "    # TODO: Add a TimeDistributed(Dense(output_dim)) layer\n",
    "    time_dense = TimeDistributed(Dense(units=units))(bn_rnn)\n",
    "    # Add softmax activation layer\n",
    "    y_pred = Activation('softmax', name='softmax')(time_dense)\n",
    "    # Specify the model\n",
    "    model = Model(inputs=input_data, outputs=y_pred)\n",
    "    model.output_length = lambda x: cnn_output_length(\n",
    "        x, kernel_size, conv_border_mode, conv_stride)\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "def cnn_output_length(input_length, filter_size, border_mode, stride,\n",
    "                       dilation=1):\n",
    "    \"\"\" Compute the length of the output sequence after 1D convolution along\n",
    "        time. Note that this function is in line with the function used in\n",
    "        Convolution1D class from Keras.\n",
    "    Params:\n",
    "        input_length (int): Length of the input sequence.\n",
    "        filter_size (int): Width of the convolution kernel.\n",
    "        border_mode (str): Only support `same` or `valid`.\n",
    "        stride (int): Stride size used in 1D convolution.\n",
    "        dilation (int)\n",
    "    \"\"\"\n",
    "    if input_length is None:\n",
    "        return None\n",
    "    assert border_mode in {'same', 'valid'}\n",
    "    dilated_filter_size = filter_size + (filter_size - 1) * (dilation - 1)\n",
    "    if border_mode == 'same':\n",
    "        output_length = input_length\n",
    "    elif border_mode == 'valid':\n",
    "        output_length = input_length - dilated_filter_size + 1\n",
    "    return (output_length + stride - 1) // stride\n",
    "\n",
    "def deep_rnn_model(input_dim, units, recur_layers, output_dim=29):\n",
    "    \"\"\" Build a deep recurrent network for speech \n",
    "    \"\"\"\n",
    "    # Main acoustic input\n",
    "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
    "    # TODO: Add recurrent layers, each with batch normalization\n",
    "    simp_rnn = GRU(units, activation='relu', return_sequences=True, implementation=2, name='rnn1')(input_data)\n",
    "    bn_rnn = BatchNormalization()(simp_rnn)\n",
    "    \n",
    "    for i in range(recur_layers):\n",
    "        if recur_layers > 1:\n",
    "            simp_rnn = GRU(units, activation='relu', return_sequences=True, implementation=2, name='rnn'+str(i+2))(bn_rnn)\n",
    "            bn_rnn = BatchNormalization()(simp_rnn)    \n",
    "    \n",
    "    # TODO: Add a TimeDistributed(Dense(output_dim)) layer\n",
    "    time_dense = TimeDistributed(Dense(units=units))(bn_rnn)\n",
    "    # Add softmax activation layer\n",
    "    y_pred = Activation('softmax', name='softmax')(time_dense)\n",
    "    # Specify the model\n",
    "    model = Model(inputs=input_data, outputs=y_pred)\n",
    "    model.output_length = lambda x: x\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "def bidirectional_rnn_model(input_dim, units, output_dim=29):\n",
    "    \"\"\" Build a bidirectional recurrent network for speech\n",
    "    \"\"\"\n",
    "    # Main acoustic input\n",
    "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
    "    # Add bidirectional recurrent layer\n",
    "    bidir_rnn = Bidirectional(GRU(units=units, activation='relu', return_sequences=True, implementation=2, name='rnn'), merge_mode='concat')(input_data)\n",
    "    # Add a TimeDistributed(Dense(output_dim)) layer\n",
    "    time_dense = TimeDistributed(Dense(units=units))(bidir_rnn)\n",
    "    # Add softmax activation layer\n",
    "    y_pred = Activation('softmax', name='softmax')(time_dense)\n",
    "    # Specify the model\n",
    "    model = Model(inputs=input_data, outputs=y_pred)\n",
    "    model.output_length = lambda x: x\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
